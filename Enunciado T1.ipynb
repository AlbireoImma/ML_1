{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n\n\n<hr style=\"height:2px;border:none\"/>\n<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2019 </h1>\n\n<H3 align='center'> Tarea 1  </H3>\n<hr style=\"height:2px;border:none\"/>\n\n**Temas**  \n* Problemas de clasificación y regresión.\n* Regresión lineal ordinaria (mínimos cuadrados).\n* Selección de atributos y parámetros de regularización en regresión lineal (Ridge y Lasso).\n* Validación cruzada.\n* Reducción de dimensionalidad: PCA e ICA.\n* Selección de hiper-parámetros estructurales de modelos de aprendizaje.\n\n** Formalidades **  \n* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n* Fecha de entrega y discusión: 4 Octubre.\n* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF393-II-2019]\n\n<hr style=\"height:2px;border:none\"/>\n\nLa tarea se divide en secciones:\n\n[1.](#primero) Máquinas de aprendizaje aplicadas a la medicina  \n[2.](#segundo) Estimación de edad de personas"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id=\"primero\"></a>\n## 1. Máquinas de aprendizaje aplicadas a la medicina\nEn el area de la salud, diagnosticar la enfermedad de una persona de forma rápida y correcta puede llegar a salvarle la vida. Los encargados de realizar estos diagnósticos, son médicos que, observando exámenes y ciertos indicadores, pueden concluir qué enfermedad presenta el paciente. Si el médico se llegase a equivocar, aparte de que el paciente pueda perder la vida, el medico podría ser demandado por negligencia arriesgando años de cárcel o pagar sumas de dinero considerable, es por estas razones que es importante no cometer errores.  \nPongámonos en el contexto de que usted es contratado para utilizar técnicas de aprendizaje de máquina para asistir en un problema médico como es la detección de enfermedades cardiacas. El diagnóstico de una enfermedad cardiaca se realiza a través de signos clínicos y resultados de pruebas médicas, los cuales usted deberá utilizar en busca del comportamiento normal y anormal de los pacientes, para así obtener un modelo que prediga si el paciente en efecto presenta una enfermedad o no.\n\n\n<img src=\"https://www.scripps.edu/_files/images/science-and-medicines/600x400_heart_illustration_xray.jpg\" width=\"35%\" />\n\n\nLos datos para trabajar junto a su documentación pueden ser descargados ejecutando los siguientes comandos en un terminal (*sistemas UNIX*):\n```\nwget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat\nwget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.doc\n```\n\n---\nCargue los datos a trabajar en un *dataframe* de pandas. Exprese las variables que tienen valores categóricos en su estructura original, para así tener una información más clara de lo que significa en un comienzo. \n```python\nimport pandas as pd\nimport numpy as np\nheaders = ['age','sex','chest_pain','blood_p','serum','blood_s','electro','max_heart', 'angina','oldpeak','slope','vessel','thal','normal']\ndf = pd.read_csv(\"heart.dat\", header=None, names=headers, sep=' ')\ndf['sex'][df['sex'] == 0] = 'female'\ndf['sex'][df['sex'] == 1] = 'male'\ndf['chest_pain'][df['chest_pain'] == 1] = 'typical angina'\ndf['chest_pain'][df['chest_pain'] == 2] = 'atypical angina'\ndf['chest_pain'][df['chest_pain'] == 3] = 'non-anginal pain'\ndf['chest_pain'][df['chest_pain'] == 4] = 'asymptomatic'\ndf['blood_s'][df['blood_s'] == 0] = 'lower than 120mg/ml'\ndf['blood_s'][df['blood_s'] == 1] = 'greater than 120mg/ml'\ndf['electro'][df['electro'] == 0] = 'normal'\ndf['electro'][df['electro'] == 1] = 'ST-T wave abnormality'\ndf['electro'][df['electro'] == 2] = 'left ventricular hypertrophy'\ndf['angina'][df['angina'] == 0] = 'no'\ndf['angina'][df['angina'] == 1] = 'yes'\ndf['slope'][df['slope'] == 1] = 'upsloping'\ndf['slope'][df['slope'] == 2] = 'flat'\ndf['slope'][df['slope'] == 3] = 'downsloping'\ndf['thal'][df['thal'] == 3] = 'normal'\ndf['thal'][df['thal'] == 6] = 'fixed defect'\ndf['thal'][df['thal'] == 7] = 'reversable defect'\n```\n\n> a) Visualice los datos trabajados describiendo el comportamiento de las variables para entender el problema al que se enfrenta. ¿Qué ocurre con el comportamiento entre pacientes sanos y enfermos? Haga gráficos si estima conveniente (histogramas, boxplots, etc).\n```python\ndf.head()\ndf.info()\ndf.describe()\n```\n\n> b) Debido a que utilizaremos modelos lineales, necesitaremos una representación adecuada de los datos. Codifique las variables con valores categóricos para ser representados como *one hot vectors*, indicando con un 1 la presencia del atributo en cuestión. Por ejemplo, si un paciente tiene el atributo \"sex: female\", quedará codificado como [0,1], mientras que si tiene el atributo \"sex: male\", quedará como [1,0]. **Explique la importancia de éste paso.**\n```python\ndf = pd.get_dummies(df)\ndf.head()\n```\n\n### Predecir la presión sanguínea\n\nEn primera instancia trabajaremos en el dominio de regresión para predecir el comportamiento de alguna de las variables involucradas con el fin de entender cómo se comportan y si es posible estimar alguna de ellas a partir de las otras. Como ayuda se le indica que una alta presión sanguínea (*blood preasure*) podría ser un indicador de riesgo en temas cardíacos, en específico, para el problema se le comenta la hipótesis de que el comportamiento anormal de la variable presión sanguínea es un buen indicador para la detección de enfermedades cardíacas. \nSu objetivo dada esta información será la de predecir el comportamiento de esta variable en función de las otras, para luego detectar qué tan distante es el valor real al valor predecido y así detectar las enfermedades.\n\n\n> c) Extraiga la información de la enfermedad cardíaca (*clase binaria*) además de la variable continua que nos intereserá predecir en esta instancia (*target*) con un modelo de regresión lineal.\n```python\nclass_label = df.pop(\"normal\").values -1 # 0 means absence, 1 means presence\nreg_label = df.pop(\"blood_p\").values\nX_data = df.values\n```\n\n> d) Cree un conjunto de pruebas para evaluar los modelos construidos en el problema. Extraiga el 30\\% de los datos del conjunto total para representar el conjunto de pruebas.\n```python\nnp.random.seed(0)\nmask_test = np.random.rand(X_data.shape[0]) < 0.30\n...\nX_train = X_data[~mask_test] \nX_test = X_data[mask_test] \n...\nreg_label_train = reg_label[~mask_test] \nreg_label_test = reg_label[mask_test]\n...\nclass_label_train = class_label[~mask_test] \nclass_label_test = class_label[mask_test]\n...\nprint(\"Train: \",X_train.shape)\nprint(\"Test: \",X_test.shape)\n```\n\n> e) Realice una estandarización normal de los datos de entrada al modelo (*input*). **Comente la importancia/conveniencia de realizar este paso**. \n```python\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nstd.fit(X_train)\nXstd_train = std.transform(X_train) \nXstd_test = std.transform(X_test)\n```\n\n> f) Realice una regresión lineal de mı́nimos cuadrados básica para predecir el nivel de presión sanguínea. Mida los errores de predicción para cada dato en el conjunto de entrenamiento. Utilizando un *quantile-quantile plot* determine si es razonable la hipótesis de normalidad sobre los residuos del modelo.\n```python\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression(fit_intercept=True)\nmodel.fit(Xstd_train, reg_label_train)\n...\nreg_pred_train = model.predict(Xstd_train)\nreg_pred_test = model.predict(Xstd_test)\n```\n\n> g) Construya una tabla con los pesos, Z-score y F-score correspondientes a cada predictor (variable), compare estos valores. ¿Qué sucede si hacemos un raking de los atributos en base al peso obtenido en la regresión? ¿Qué variables están más correlacionadas con la respuesta?\n\n\n> h) Para evaluar la calidad de las predicciones del modelo sobre el problema utilice el error absoluto medio (*mean absolute error*). Comente los resultados sobre en ambos conjuntos y la interpretación que se le da a la métrica de evaluación en el problema.\n```python\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nprint(\"MSE train: \", mean_squared_error(reg_label_train, reg_pred_train))\nprint(\"MSE test: \", mean_squared_error(reg_label_test, reg_pred_test))\n```\n\n> i) Estime la calidad del modelo usando validación cruzada con un número de *fold* igual a $K=1$ (*leave-one-out*) y $K=5$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Compare esta estimación *vs* la calidad real (en conjunto de pruebas) y concluya.\n```python\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=K)\nmse_cv = 0\nfor train, val in kf.split(Xstd_train):\n    linreg = LinearRegression(fit_intercept=True)\n    linreg.fit(Xstd_train[train], reg_label_train[train])\n    yhat_kfold_val = linreg.predict(Xstd_train[val])\n    mse_fold =  np.mean( np.square(yhat_kfold_val - reg_label_train[val]) )\n    mse_cv += mse_fold\nmse_cv = mse_cv / K\n```\n\n> j) Debido a la creación de varias columnas *dummys* en el punto b), experimente con técnicas de regularización para mejorar el desempeño de su modelo. Para ésto ajuste un modelo lineal utilizando \"*Ridge Regression*\", es decir, regularizando con la norma $l_2$, varíe los parámetros de regularización si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. \n```python\nfrom sklearn.linear_model import Ridge\nalphas_ = np.logspace(5,0, base=10)\ncoefs = []\nmodel = Ridge(fit_intercept=True, solver='svd')\nfor a in alphas_:\n    model.set_params(alpha=a)\n    model.fit(Xstd_train, reg_label_train)\n    coefs.append(model.coef_)\nimport matplotlib.pyplot as plt\nnames_regressors = df.columns\nplt.figure(figsize=(15,7))\nfor y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n    plt.plot(alphas_, y_arr, label=label)\nplt.legend()\nplt.xscale('log')\nplt.title('Regularization Path RIDGE')\nplt.legend(loc='lower right')\nplt.show()\n```\n\n> k) Ahora experimente regularizando con la norma $l_1$, lo que corresponde a utilizar el método \"*Lasso*\". Vuelva a realizar el gráfico mostrando los coeficientes obtenidos, describa lo que observa. ¿Es más efectivo *Lasso* para seleccionar atributos?\n```python\nfrom sklearn.linear_model import Lasso\nalphas_ = np.logspace(2,-2,base=10)\ncoefs = []\nmodel = Lasso(fit_intercept=True)\nfor a in alphas_:\n    model.set_params(alpha=a)\n    model.fit(Xstd_train, reg_label_train)\n    coefs.append(model.coef_)\n... #plot again\n```\n\n> l) Evalúe la calidad de estos dos modelos en ambos conjuntos a distintos valores del parámetro de regularización. Haga uso de la *widget* interactiva de *ipython*. Comente ¿Con qué valor de *alpha* se quedaría en cada caso?\n```python\nfrom ipywidgets import interactive\ndef train_model(param):\n    model = #define the model (Ridge and Lasso)\n    A = 10**(param)\n    print(\"Param alpha= \",A)\n    model.set_params(alpha=A)\n    model.fit(Xstd_train, reg_label_train)\n    print(\"MSE train: \", mean_squared_error(reg_label_train, model.predict(Xstd_train) ))\n    print(\"MSE test: \", mean_squared_error(reg_label_test, model.predict(Xstd_test) ))\np_min = -10 #define your range\np_max = 10 #define your range\ninteractive(train_model, param=(p_min,p_max))\n```\n\n> m) De manera más estricta un médico le solicita un modelo que solo cuente con 5 características (variables) para predecir el nivel de presión sanguínea. Usted bien conoce un método que selecciona características de manera iterativa (*greedy*), con la idea de que la característica seleccionada tenga el mejor aporte sobre el desempeño del modelo. Construya una función que implemente *Forward Step-wise Selection* (FSS) sobre el modelo de regresión lineal clásico.  Para seleccionar localmente una característica, **proponga/implemente un criterio distinto al utilizado en el código de ejemplo** (**no** utilice el conjunto de pruebas). Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo.\n```python\ndef fss(x, y, names_x, k = 10000):\n    p = x.shape[1]-1\n    k = min(p, k)\n    names_x = np.array(names_x)\n    remaining = range(0, p)\n    selected = [p]\n    current_score = best_new_score = 0.0\n    while remaining and len(selected)<=k :\n        score_candidates = []\n        for candidate in remaining:\n            model = LinearRegression(fit_intercept=True, n_jobs=1)\n            indexes = selected + [candidate]\n            x_train = x[:,indexes]\n            predictions_train = model.fit(x_train, y).predict(x_train)\n            residuals_train =  predictions_train - y\n            error_candidate =  np.mean(np.power(residuals_train, 2))\n            score_candidates.append((error_candidate, candidate))\n        score_candidates.sort()\n        score_candidates[:] = score_candidates[::-1]\n        best_new_score, best_candidate = score_candidates.pop()\n        remaining.remove(best_candidate)\n        selected.append(best_candidate)\n        print \"selected = %s ...\"%names_x[best_candidate]\n        print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n    return selected\nfeatures_fss = fss(Xstd_train, reg_label_train, names_regressors)\nneed_feat = features_fss[:5]\n```\n\n> n) Realice otra modificación al algoritmo FSS anterior, en donde se deba entrenar el modelo predictor una sola vez. Cree alguna huerística de selección que le permita realizar ésto.\n\n> o) Realice una modificación a los datos y agregue entre 10 a 100 atributos falsos, es decir, atributos aleatorios generados que no tienen relación con la variable de predicción (*target*). Para ésto utilice una distribución normal con valor esperado diferente de 0 y una cierta desviación estándar. Utilice alguna de las técnicas de selección de atributos (Ridge, Lasso, FSS) para evaluar la efectividad en eliminar estos atributos falsos ¿Depende del nivel de ruido (desviación estándar)?\n```python\nD = #number of fake features\nF = np.random.normal(loc = mu, scale = std, size=(N,D) ) #fake features\nX_new_train= np.concatenate([Xstd_train, F], axis=-1)\n```\n\n\n### Detectar una enfermedad \nCon toda la información obtenida de la experimentación previa, deberá hacer la predicción de la enfermedad cardíaca, ésto es un problema binario de clasificación de dos clases (presencia o ausencia de la enfermedad). Para explorar la hipótesis que le fue entregada en un inicio, de que el comportamiento anormal (*outlier*) de presión sanguínea sobre las personas es un indicio de alguna enfermedad, deberá utilizar los datos de los pacientes que se encuentran sanos (comportamiento normal).\n\n> p) Entrene un modelo de regresión lineal, el mejor explorado en la experimentación previa, para predecir la presión sanguínea de los pacientes sanos, así obtener un modelo que estima cuál debiera ser el nivel sanguíneo en base al resto de información del paciente.\n```python\nmask_norm = class_label_train == 0 \nmodel = #choose yor model..\nmodel.fit(Xstd_train[mask_norm], reg_label_train[mask_norm])\n...\nblood_p_tr = model.predict(Xstd_train) \nblood_p_te = model.predict(Xstd_test) \n```\n\n> q) Realice una clasificación de los pacientes a través de definir un umbral de decisión óptimo sobre la presión sanguínea estimada por el modelo. Por ejemplo, una cantidad mayor a $p$ es considerado como anormal (enfermo). Para ésto utilice la distribución predicha de este atributo para poder separar correctamente entre los dos tipos de comportamiento, normal (sano) y anormal (enfermo).\n```python\nimport seaborn as sns\nsns.distplot(blood_p_tr[mask_norm], label=\"normal behavior\")\nsns.distplot(blood_p_tr[~mask_norm], label=\"ill person behavior\")\nplt.show()\ndef predict_umbr(data, umbral_up, umbral_low):\n    preds = []\n    for value in data:\n        if value > umbral_up or value < umbral_low:\n            preds.append(1) #presencia\n        else:\n            preds.append(0)\n    return np.asarray(preds)\npred_train = predict_umbr(blood_p_tr, p_up, p_low)\npred_test = predict_umbr(blood_p_te, p_up, p_low)\n```\n\n> r) Mida la calidad de la clasificación entregada a través de la exactitud (*accuracy*) sobre ambos conjuntos. Evalúe si es necesario variar la decisión sobre el umbral del punto anterior. *Recuerde que, al ser un problema binario, el mínimo que se espera es por sobre 50\\%*\n```python\nfrom sklearn.metrics import accuracy_score\nprint(\"Score train: \",accuracy_score(class_label_train, pred_train))\nprint(\"Score test: \",accuracy_score(class_label_test, pred_test)) \n```\n\n> s) Compare su *framework* de clasificación con un modelo lineal simple de clasificación binaria como el *perceptrón*, el cual se entrenará para aprender directamente la tarea (de manera supervisada), sin utilizar la información de presión sanguínea. Comente sobre las diferencias, ventajas y desventajas, de cada *approach*.\n```python\nfrom sklearn.linear_model import Perceptron\nmodel = Perceptron(fit_intercept=True, eta0=1.0, max_iter=1000, n_jobs=-1)\nmodel.fit(Xstd_train, class_label_train)\npred_train = model.predict(Xstd_train) \npred_test = model.predict(Xstd_test)\nprint(\"Score train: \",accuracy_score(class_label_train, pred_train))\nprint(\"Score test: \",accuracy_score(class_label_test, pred_test)) \n```\n\n> t) Para poder darle una explicación más visual a la clasificación de ambos modelos, y así entender mejor dónde podría estar el error, proyecte los datos en 2 dimensiones. Utilice la técnica de reducción de dimensionalidad **PCA** para representar los datos en las dimensiones deseadas. Comente sobre el comportamiento, puede colorear los datos dado el estado del paciente (enfermedad) y/o la predicción de alguno de los modelos (Perceptrón o con umbral).\n```python\nfrom sklearn.decomposition import PCA\nd = 2\npca_model = PCA(n_components=d)\npca_model.fit(Xstd_train)\nX_pca_train = pca_model.transform(Xstd_train)\nX_pca_test = pca_model.transform(Xstd_test)\nplt.scatter(X_pca_train[:,0], X_pca_train[:,1])\nplt.show()\n```\n\n> u) Vuelve a realizar lo anterior pero con otra técnica de reducción de dimensionalidad, como por ejemplo **ICA** [[3]](#refs). Comente\n```python\nfrom sklearn.decomposition import FastICA\n...\n```\n\n> v) ¿Qué tanto se ve afectada la calidad de predicción si se utiliza la representación reducida generada por PCA vs la representación original? ¿Es esperable este fenómeno? ¿Podría mejorar la calidad de predicción? Proponga e implemente un criterio para seleccionar el número de componentes $d$ en PCA. Comente"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id=\"segundo\"></a>\n## 2. Estimación de edad de personas\nEl problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante dificil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n\n<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n\n\nEn esta actividad trabajaremos con unos datos (imágenes) en el **objetivo** de predecir la **edad** (*target value*) de la persona presente en la imagen. Los datos corresponden a 3640 imágenes de rostros de personas extraídos de la plataforma Flickr, pero, debido a que trabajamos con redes *feed forward*, se trabajará con representaciones de alto nivel, extraídas manualmente (no-aprendibles). Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n```\nwget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n```\n\nSe trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:\n```python\nimport scipy.io as sio\nmat_file = sio.loadmat(\"event.mat\")\n```\nMientras que para acceder a la información como tal:\n```python\ndata = mat_file[\"trcoll\"][0][0] # is \"tecoll\" for testing set\nage_true = data[1] #target\n...\ngenFeat = data[0]   # Contextual features\nffcoefs = data[3]   # Fisherface space\nfaceGist = data[4]  # GIST features\n...\n```\n\nPara descripción sobre las columnas están en el archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n```\nwget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n```\n\nExisten distintas representaciones (descriptores) que usted podrá trabajar y entregársela como *input* a su modelo. Está la libertad de cómo desea trabajar este problema para detectar la edad de la persona, ya sea combinando los descriptores, teniendo un modelo para cada uno, definiendo rangos de edad o cualquier idea que se le ocurra. \n\n#### Importante\n* Recuerde que el conjunto de pruebas está para evaluar su modelo final, **no puede tomar decisiones basadas en este conjunto**. *Sin embargo, Puede generar un conjunto de validación desde el conjunto de entrenamiento o utilizar validación cruzada*.\n\n* La métrica de evaluación será MAPE (*Mean Absolute Percetage Error*).\n```python\nimport numpy as np\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n```\n* Se evaluará la extensión de su experimentación, la correctitud y su creatividad al desarrollar la actividad.\n\n#### --- Bonus ---\nSi desea comparar la calidad de solución respecto a otros estudiantes podrá realizar un *submission* de sus resultados en el conjunto de pruebas en la plataforma de __[Kaggle](https://www.kaggle.com/c/t1-ml/)__ a través del siguiente __[link](https://www.kaggle.com/t/3f3c4a759ec3482ab06c06ec91187742)__.\n\nEl archivo de *submission* debe contener una columna de *id* asociado a cada conjunto de pruebas, iniciando en 1, se puede generar de la siguiente manera:\n```python\nids = np.arange(1, 1+y_pred.shape[0]).reshape(-1,1)\nsub_est = np.concatenate([ids, y_pred], axis=-1)\nimport pandas as pd\ndf_aux = pd.DataFrame(sub_est, columns=[\"id\",\"age\"])\ndf_aux.to_csv(\"test_estimation.csv\", index=False)\n```\n\n> Para los 3 primeros lugares se otorgará 5, 10 y 15 puntos respectivos en su nota final de esta tarea. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<a id=\"refs\"></a>\n## Referencias\n[1] Hastie, T.; Tibshirani, R., Friedman, J. (2009), *The Elements of Statistical Learning*, Second Edition.\nSpringer New York Inc.  \n[2] Ethem Alpaydin. *Machine Learning*. 2014.  \n[3] Hyvärinen, A., & Oja, E. (2000). *Independent component analysis: algorithms and applications*. Neural networks, 13(4-5), 411-430."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}